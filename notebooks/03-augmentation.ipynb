{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "\n",
    "Images are easier to manipulate than text.\n",
    "If I take an image I can make it a bit darker and it is still an image of the same thing.\n",
    "There are many different ways I can change an image without breaking it.\n",
    "\n",
    "A nice set of transforms can be viewed [in the fastai docs](https://docs.fast.ai/vision.transform.html#List-of-transforms).\n",
    "\n",
    "It's desirable to randomly apply these transformations, to increase the range of images that can be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p massive-data/cat\n",
    "!wget https://github.com/matthewfranglen/interactive-image-classification/raw/master/notebooks/massive-data/cat/cat.jpg -O massive-data/cat/cat.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(image: torch.Tensor) -> PIL.Image:\n",
    "    # the rescaling also reverses the normalization (close enough)\n",
    "    image -= image.min()\n",
    "    image /= image.max()\n",
    "    return transforms.functional.to_pil_image(image.cpu(), 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(\"massive-data/cat/cat.jpg\") ; image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.RandomHorizontalFlip(p=1)(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.RandomAffine(degrees=90.)(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These augmentations are applied to the image before it is transformed into a tensor.\n",
    "This is because it's much easier to apply these changes using the python image library instead of operating over the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.rotate(angle=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.DatasetFolder(\n",
    "    root='massive-data',\n",
    "    loader=PIL.Image.open,\n",
    "    extensions=('jpg',),\n",
    "    transform=transforms.Compose([\n",
    "        # This lets you randomly apply all the transformations in this list.\n",
    "        # The test is not once per transform, it either skips all transforms or applies all transforms.\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n",
    "        ]),\n",
    "        \n",
    "        # This is a combination of RandomApply and HorizontalFlip, by default has a 50% chance of flipping the image\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "image, target = next(iter(train_ds))\n",
    "print(train_ds.classes[target])\n",
    "to_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
