{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Connections\n",
    "\n",
    "![skip connection](http://chaosmail.github.io/images/deep-learning/residual.png)\n",
    "\n",
    "These can be used as part of your repeated block.\n",
    "The stride cannot be part of the inner operations, otherwise the two tensors would not be the same shape.\n",
    "\n",
    "The image above shows addition, however concatenation is more common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipSequential(nn.Sequential):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_prime = super().forward(x)\n",
    "        return torch.cat([x, x_prime], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeating_block(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        SkipSequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(1, 1),\n",
    "                padding_mode='reflect',\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(1, 1),\n",
    "                padding_mode='reflect',\n",
    "            ),\n",
    "        ),\n",
    "        nn.Tanh(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels + out_channels, # THIS HAS CHANGED\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.Tanh(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing to realise here is that the number of channels grows immediately after the skip connection.\n",
    "\n",
    "If you do forget this then you'll see an error like:\n",
    "\n",
    "```\n",
    "RuntimeError: Given groups=1, weight of size [16, 16, 3, 3], expected input[128, 24, 19, 19] to have 16 channels, but got 24 channels instead\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
