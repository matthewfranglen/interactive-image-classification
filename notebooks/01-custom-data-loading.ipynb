{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Training your own models might be difficult if you can't load the data.\n",
    "This notebook covers how the dataloader works in some detail and how you can use it to load your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Right now we are going to cover:\n",
    "\n",
    " * Custom data - how you can load your own images\n",
    " * Normalization - altering image data to make it easier to process\n",
    " * Augmentation - altering image data to increase the data quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(image: torch.Tensor) -> PIL.Image:\n",
    "    # the rescaling also reverses the normalization (close enough)\n",
    "    image -= image.min()\n",
    "    image /= image.max()\n",
    "    return transforms.functional.to_pil_image(image.cpu(), 'RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Custom Data\n",
    "\n",
    "To have a custom data loader (`torch.utils.data.DataLoader`) you just need a custom data set (`datasets.VisionDataset` or even `data.Dataset`).\n",
    "A data set can be used by a data loader.\n",
    "\n",
    "Lets start by looking at the CIFAR dataset, then work back from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.CIFAR10(\n",
    "    'data',\n",
    "    download=True,\n",
    "    train=True,\n",
    ")\n",
    "# uncomment the following line to see the source code\n",
    "# train_ds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.__len__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.__getitem__??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the two methods you need to implement.\n",
    "The `__get_item__` method should also apply the transformations, as seen above.\n",
    "\n",
    "Where does the data in `self.data` come from though?\n",
    "It is loaded as the class is created.\n",
    "When you create your own dataset you do not need to load all the data at the start - CIFAR10 is relatively small so it can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So we can write an equivalent loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleLoader(datasets.VisionDataset):\n",
    "    def __init__(self, image, label, transform=None, target_transform=None):\n",
    "        # the transform and target_transform arguments get saved to self as self.transform and self.target_transform\n",
    "        super().__init__(image, transform=transform, target_transform=target_transform)\n",
    "        # load or prepare your own data after this\n",
    "        self.image = PIL.Image.open(image)\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.image\n",
    "        target = self.label\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ds = ExampleLoader('massive-data/cat/cat.jpg', 0, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = next(iter(example_ds))\n",
    "\n",
    "print(target)\n",
    "to_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a working dataset and can be added to a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dl = torch.utils.data.DataLoader(example_ds)\n",
    "images, targets = next(iter(example_dl))\n",
    "\n",
    "images.shape, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dl = torch.utils.data.DataLoader(example_ds, batch_size=4)\n",
    "images, targets = next(iter(example_dl))\n",
    "\n",
    "images.shape, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see it works just fine.\n",
    "The data loader will not repeat the dataset in order to fill out a batch.\n",
    "\n",
    "Lets see if we can make this easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.DatasetFolder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleFolderLoader(datasets.DatasetFolder):\n",
    "    def __init__(self, folder, transform=None, target_transform=None):\n",
    "        super().__init__(root=folder, loader=PIL.Image.open, extensions=('jpg',), transform=transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_folder_ds = ExampleFolderLoader('massive-data', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = next(iter(example_folder_ds))\n",
    "\n",
    "print(target) # it has turned this into an index automatically\n",
    "print(example_folder_ds.classes[target]) # this is how you find the label\n",
    "to_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_folder_no_class_ds = datasets.DatasetFolder(\n",
    "    root='massive-data',\n",
    "    loader=PIL.Image.open,\n",
    "    extensions=('jpg',),\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = next(iter(example_folder_no_class_ds))\n",
    "\n",
    "print(target) # it has turned this into an index automatically\n",
    "print(example_folder_no_class_ds.classes[target]) # this is how you find the label\n",
    "to_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The Simplest Dataset\n",
    "\n",
    "I strongly recommend you use one of the loading techniques described above.\n",
    "\n",
    "It is possible to use a list as a dataloader.\n",
    "It has a length and can get things by index.\n",
    "You would have to prepare all the data in advance, and hold it all in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = [\n",
    "    (transforms.functional.to_tensor(PIL.Image.open('massive-data/cat/cat.jpg')), 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dl = torch.utils.data.DataLoader(list_ds, batch_size=4)\n",
    "images, targets = next(iter(list_dl))\n",
    "\n",
    "images.shape, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm showing you this to show you how simple a dataset really is.\n",
    "Anything that is like a list of `(input, target)` is a dataset.\n",
    "\n",
    "Using the \"real\" dataset classes makes it easier to apply the transformations, and we will see how valuable those are next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
