{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP\n",
    "\n",
    "# SECRET\n",
    "\n",
    "# NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![more layers](https://i.redd.it/5193db0avbey.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "if not CUDA_AVAILABLE:\n",
    "    print(\"If you are running this on Google Colab then\")\n",
    "    print(\"Menu -> Runtime -> Change runtime type -> Hardware Accelerator -> GPU\")\n",
    "    print(\"Then try this again...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(\n",
    "    model: nn.Module,\n",
    "    valid: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    correct, incorrect = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(valid, desc=f\"validation\"):\n",
    "            if CUDA_AVAILABLE:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            matching = torch.eq(targets, outputs.argmax(dim=1)).sum().item()\n",
    "\n",
    "            correct += matching\n",
    "            incorrect += inputs.shape[0] - matching\n",
    "    \n",
    "    return correct / (correct + incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train: torch.utils.data.DataLoader,\n",
    "    valid: torch.utils.data.DataLoader,\n",
    "    epochs: int = 4,\n",
    "    lr: float = 0.001\n",
    ") -> None:\n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_batches = len(train)\n",
    "    train_loss = 0.\n",
    "\n",
    "    valid_batches = len(valid)\n",
    "    valid_loss = 0.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = eval_loss = 0.\n",
    "\n",
    "        for inputs, targets in tqdm(train, desc=f\"train {epoch}\"):\n",
    "            if CUDA_AVAILABLE:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss_value = loss(outputs, targets)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss_value.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(valid, desc=f\"valid {epoch}\"):\n",
    "                if CUDA_AVAILABLE:\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss_value = loss(outputs, targets)\n",
    "                valid_loss += loss_value.item()\n",
    "        \n",
    "        # remember tensorboardx makes pretty graphs\n",
    "        train_loss /= train_batches\n",
    "        valid_loss /= valid_batches\n",
    "        valid_score = score(model, valid)\n",
    "        print()\n",
    "        print(f\"train loss: {train_loss:.2e}\")\n",
    "        print(f\"valid loss: {valid_loss:.2e}\")\n",
    "        print(f\"valid score: {valid_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.CIFAR10(\n",
    "    'data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.Compose([\n",
    "        # This lets you randomly apply all the transformations in this list.\n",
    "        # The test is not once per transform, it either skips all transforms or applies all transforms.\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n",
    "        ]),\n",
    "        \n",
    "        # This is a combination of RandomApply and HorizontalFlip, by default has a 50% chance of flipping the image\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "\n",
    "        # We can only train with tensors, so we convert the image to a tensor.\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "        # A very good thing to do is to normalize the tensors.\n",
    "        # This ensures the resulting tensors have a mean of 0 and a standard deviation of 1.\n",
    "        # For pre-existing datasets you can look up the normalization values, or you can calculate them like I did above.\n",
    "        transforms.Normalize(mean=(0.49139968, 0.48215841, 0.44653091), std=(0.24703223, 0.24348513, 0.26158784)),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "valid_ds = datasets.CIFAR10(\n",
    "    'data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # Must apply the same normalization!\n",
    "        transforms.Normalize(mean=(0.49139968, 0.48215841, 0.44653091), std=(0.24703223, 0.24348513, 0.26158784)),\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model is here so that it is created fresh every time you evaluate it\n",
    "\n",
    "ACTIVATION_FN = nn.LeakyReLU()\n",
    "\n",
    "def conv2_same(in_channels: int, out_channels: int, kernel: Tuple[int, int] = (3, 3)) -> nn.Module:\n",
    "    padding = (int(kernel[0] / 2), int(kernel[1] / 2))\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel,\n",
    "            padding=padding,\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        ACTIVATION_FN,\n",
    "    )\n",
    "\n",
    "def conv2_stride(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        ACTIVATION_FN,\n",
    "    )\n",
    "\n",
    "class SkipSequential(nn.Sequential):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_prime = super().forward(x)\n",
    "        return torch.cat([x, x_prime], dim=1)\n",
    "\n",
    "def intro(out_channels: int) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        conv2_same(3, out_channels, kernel=(7, 7)),\n",
    "        ACTIVATION_FN,\n",
    "    )\n",
    "\n",
    "def classification(in_channels: int, out_channels: int = 10) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.AdaptiveMaxPool2d(output_size=(1,1)), # could try AdaptiveAvg\n",
    "        nn.Flatten(), # SNEAKY\n",
    "        nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "    )\n",
    "\n",
    "def pyramid_block(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    mid_channels = in_channels + ((out_channels - in_channels) // 2)\n",
    "    # outer -> middle -> inner -> middle -> outer\n",
    "    \n",
    "    # input_size: out_channels\n",
    "    # output_size: out_channels + out_channels\n",
    "    inner = SkipSequential(\n",
    "        conv2_stride(mid_channels, mid_channels),\n",
    "        conv2_same(mid_channels, out_channels),\n",
    "        nn.Upsample(scale_factor=2),\n",
    "    )\n",
    "    \n",
    "    # input_size: in_channels\n",
    "    # output_size: in_channels + mid_channels + out_channels\n",
    "    middle = SkipSequential(\n",
    "        conv2_stride(in_channels, mid_channels),\n",
    "        inner,\n",
    "        nn.Upsample(scale_factor=2),\n",
    "    )\n",
    "    \n",
    "    # input_size: in_channels\n",
    "    # output_size: out_channels\n",
    "    outer = nn.Sequential(\n",
    "        middle,\n",
    "        conv2_stride(\n",
    "            in_channels=in_channels + mid_channels + out_channels,\n",
    "            out_channels=out_channels,\n",
    "        ),\n",
    "    )\n",
    "    return outer\n",
    "\n",
    "def repeating_block(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    mid_channels = in_channels + ((out_channels - in_channels) // 2)\n",
    "    return nn.Sequential(\n",
    "        conv2_same(in_channels, mid_channels),\n",
    "        conv2_same(mid_channels, mid_channels),\n",
    "        conv2_stride(mid_channels, out_channels),\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    intro(64),\n",
    "    pyramid_block(64, 64), # image now 16x16\n",
    "    pyramid_block(64, 128), # image now 8x8\n",
    "    pyramid_block(128, 256), # image now 4x4\n",
    "    repeating_block(256, 512), # image now 2x2\n",
    "    classification(512)\n",
    ")\n",
    "\n",
    "if CUDA_AVAILABLE:\n",
    "    model = model.cuda()\n",
    "\n",
    "train(model, train_dl, valid_dl, epochs=4, lr=0.001)\n",
    "score(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    intro(64),\n",
    "    pyramid_block(64, 64), # image now 16x16\n",
    "    pyramid_block(64, 128), # image now 8x8\n",
    "    pyramid_block(128, 256), # image now 4x4\n",
    "    repeating_block(256, 512), # image now 2x2\n",
    "    classification(512)\n",
    ")\n",
    "\n",
    "if CUDA_AVAILABLE:\n",
    "    model = model.cuda()\n",
    "\n",
    "train(model, train_dl, valid_dl, epochs=20, lr=0.001)\n",
    "score(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model is here so that it is created fresh every time you evaluate it\n",
    "\n",
    "ACTIVATION_FN = nn.LeakyReLU()\n",
    "\n",
    "def conv2_same(in_channels: int, out_channels: int, kernel: Tuple[int, int] = (3, 3), dropout: bool = True) -> nn.Module:\n",
    "    padding = (int(kernel[0] / 2), int(kernel[1] / 2))\n",
    "    core = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel,\n",
    "            padding=padding,\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        ACTIVATION_FN,\n",
    "    )\n",
    "    if not dropout:\n",
    "        return core\n",
    "    return nn.Sequential(nn.Dropout(), core)\n",
    "\n",
    "def conv2_stride(in_channels: int, out_channels: int, dropout: bool = True) -> nn.Module:\n",
    "    core = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        ACTIVATION_FN,\n",
    "    )\n",
    "    if not dropout:\n",
    "        return core\n",
    "    return nn.Sequential(nn.Dropout(), core)\n",
    "\n",
    "class SkipSequential(nn.Sequential):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_prime = super().forward(x)\n",
    "        return torch.cat([x, x_prime], dim=1)\n",
    "\n",
    "def intro(out_channels: int) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        conv2_same(3, out_channels, kernel=(7, 7), dropout=False),\n",
    "        ACTIVATION_FN,\n",
    "    )\n",
    "\n",
    "def classification(in_channels: int, out_channels: int = 10) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.AdaptiveMaxPool2d(output_size=(1,1)), # could try AdaptiveAvg\n",
    "        nn.Flatten(), # SNEAKY\n",
    "        nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "    )\n",
    "\n",
    "def pyramid_block(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    mid_channels = in_channels + ((out_channels - in_channels) // 2)\n",
    "    # outer -> middle -> inner -> middle -> outer\n",
    "    \n",
    "    # input_size: out_channels\n",
    "    # output_size: out_channels + out_channels\n",
    "    inner = SkipSequential(\n",
    "        conv2_stride(mid_channels, mid_channels),\n",
    "        conv2_same(mid_channels, out_channels),\n",
    "        nn.Upsample(scale_factor=2),\n",
    "    )\n",
    "    \n",
    "    # input_size: in_channels\n",
    "    # output_size: in_channels + out_channels + out_channels\n",
    "    middle = SkipSequential(\n",
    "        conv2_stride(in_channels, mid_channels),\n",
    "        inner,\n",
    "        nn.Upsample(scale_factor=2),\n",
    "    )\n",
    "    \n",
    "    # input_size: in_channels\n",
    "    # output_size: out_channels\n",
    "    outer = nn.Sequential(\n",
    "        middle,\n",
    "        conv2_stride(\n",
    "            in_channels=in_channels + mid_channels + out_channels,\n",
    "            out_channels=out_channels,\n",
    "        ),\n",
    "    )\n",
    "    return outer\n",
    "\n",
    "def repeating_block(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    mid_channels = in_channels + ((out_channels - in_channels) // 2)\n",
    "    return nn.Sequential(\n",
    "        conv2_same(in_channels, mid_channels),\n",
    "        conv2_same(mid_channels, mid_channels),\n",
    "        conv2_stride(mid_channels, out_channels),\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    intro(64),\n",
    "    pyramid_block(64, 64), # image now 16x16\n",
    "    pyramid_block(64, 128), # image now 8x8\n",
    "    pyramid_block(128, 256), # image now 4x4\n",
    "    repeating_block(256, 512), # image now 2x2\n",
    "    classification(512)\n",
    ")\n",
    "\n",
    "if CUDA_AVAILABLE:\n",
    "    model = model.cuda()\n",
    "\n",
    "train(model, train_dl, valid_dl, epochs=5, lr=0.01)\n",
    "train(model, train_dl, valid_dl, epochs=5, lr=0.001)\n",
    "train(model, train_dl, valid_dl, epochs=5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
