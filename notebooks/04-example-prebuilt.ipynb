{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Network\n",
    "\n",
    "We are now going to train a network using the complete data set / data loader that we covered to date.\n",
    "This will run on CIFAR10 which is harder to correctly classify than MNIST.\n",
    "The images are still very small so the downloaded data will be small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "if not CUDA_AVAILABLE:\n",
    "    print(\"If you are running this on Google Colab then\")\n",
    "    print(\"Menu -> Runtime -> Change runtime type -> Hardware Accelerator -> GPU\")\n",
    "    print(\"Then try this again...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(image: torch.Tensor) -> PIL.Image:\n",
    "    # the rescaling also reverses the normalization (close enough)\n",
    "    image -= image.min()\n",
    "    image /= image.max()\n",
    "    return transforms.functional.to_pil_image(image.cpu(), 'RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Because the images are so very small (32x32) we can't use any augmentation that would rotate or shift the image, as that could well make the image impossible to recognize.\n",
    "We can use color jittering as that alters the entire image consistently, and we can flip horizontally.\n",
    "\n",
    "It's generally a bad idea to flip photos vertically, as you don't usually take a photo upside down.\n",
    "There are certain situations were that could be appropriate - satellite images or individual cell images are good examples.\n",
    "Good augmentation relies on your knowledge of the problem space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 341 mb dataset\n",
    "\n",
    "train_ds = datasets.CIFAR10(\n",
    "    'data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transforms.Compose([\n",
    "        # This lets you randomly apply all the transformations in this list.\n",
    "        # The test is not once per transform, it either skips all transforms or applies all transforms.\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n",
    "        ]),\n",
    "        \n",
    "        # This is a combination of RandomApply and HorizontalFlip, by default has a 50% chance of flipping the image\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "\n",
    "        # We can only train with tensors, so we convert the image to a tensor.\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "        # A very good thing to do is to normalize the tensors.\n",
    "        # This ensures the resulting tensors have a mean of 0 and a standard deviation of 1.\n",
    "        # For pre-existing datasets you can look up the normalization values, or you can calculate them like I did above.\n",
    "        transforms.Normalize(mean=(0.49139968, 0.48215841, 0.44653091), std=(0.24703223, 0.24348513, 0.26158784)),\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=128, shuffle=True, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        'data',\n",
    "        download=True,\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # Must apply the same normalization!\n",
    "            transforms.Normalize(mean=(0.49139968, 0.48215841, 0.44653091), std=(0.24703223, 0.24348513, 0.26158784)),\n",
    "        ]),\n",
    "    ),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same resnet model as before, this shows how to use torch.hub\n",
    "model = torch.hub.load(\n",
    "    github='pytorch/vision:v0.6.0',\n",
    "    model='resnet18',\n",
    "    pretrained=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA_AVAILABLE:\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train: torch.utils.data.DataLoader,\n",
    "    valid: torch.utils.data.DataLoader,\n",
    "    epochs: int = 4,\n",
    "    lr: float = 0.001\n",
    ") -> None:\n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_batches = len(train)\n",
    "    train_loss = 0.\n",
    "\n",
    "    valid_batches = len(valid)\n",
    "    valid_loss = 0.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = eval_loss = 0.\n",
    "\n",
    "        for inputs, targets in tqdm(train, desc=f\"train {epoch}\"):\n",
    "            if CUDA_AVAILABLE:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss_value = loss(outputs, targets)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss_value.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(valid, desc=f\"valid {epoch}\"):\n",
    "                if CUDA_AVAILABLE:\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss_value = loss(outputs, targets)\n",
    "                valid_loss += loss_value.item()\n",
    "        \n",
    "        # remember tensorboardx makes pretty graphs\n",
    "        train_loss /= train_batches\n",
    "        valid_loss /= valid_batches\n",
    "        print(f\"\\rtrain loss: {train_loss:.2e}\")\n",
    "        print(f\"valid loss: {valid_loss:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(\n",
    "    model: nn.Module,\n",
    "    valid: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    correct, incorrect = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(valid, desc=f\"validation\"):\n",
    "            if CUDA_AVAILABLE:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            matching = torch.eq(targets, outputs.argmax(dim=1)).sum().item()\n",
    "\n",
    "            correct += matching\n",
    "            incorrect += inputs.shape[0] - matching\n",
    "    \n",
    "    return correct / (correct + incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't a great result.\n",
    "The CIFAR-10 stats on Wikipedia suggest this is state of the art for 2010.\n",
    "\n",
    "The Resnet 18 architecture is very basic though.\n",
    "What we need to do now is improve it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
