{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Pyramid\n",
    "\n",
    "![feature pyramid](https://lilianweng.github.io/lil-log/assets/images/featurized-image-pyramid.png)\n",
    "\n",
    "This is a more advanced approach.\n",
    "We can stride down and up _within a repeated block_.\n",
    "Skip connections prevent losing too much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipSequential(nn.Sequential):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_prime = super().forward(x)\n",
    "        return torch.cat([x, x_prime], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_block(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    # outer -> middle -> inner -> middle -> outer\n",
    "    \n",
    "    # input_size: out_channels\n",
    "    # output_size: out_channels + out_channels\n",
    "    inner = SkipSequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.Tanh(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.Tanh(),\n",
    "        nn.Upsample(scale_factor=2)\n",
    "    )\n",
    "    \n",
    "    # input_size: in_channels\n",
    "    # output_size: in_channels + out_channels + out_channels\n",
    "    middle = SkipSequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.Tanh(),\n",
    "        inner,\n",
    "        nn.Upsample(scale_factor=2)\n",
    "    )\n",
    "    \n",
    "    # input_size: in_channels\n",
    "    # output_size: out_channels\n",
    "    outer = nn.Sequential(\n",
    "        middle,\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels + out_channels + out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='reflect',\n",
    "        ),\n",
    "        nn.Tanh(),\n",
    "    )\n",
    "    return outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Because this shrinks and expands, there is a point past which this will not work.\n",
    "This block is also very sensitive to the input image size - rounding errors frequently lead to misalignment between the different layers, which then breaks the skip connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid_block(3, 16)(torch.zeros(1, 3, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid_block(3, 16)(torch.zeros(1, 3, 4, 4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
